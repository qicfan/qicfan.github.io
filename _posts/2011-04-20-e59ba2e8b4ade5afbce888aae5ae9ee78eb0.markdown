---
author: qicfan
comments: true
date: 2011-04-20 14:09:25+00:00
layout: post
slug: '%e5%9b%a2%e8%b4%ad%e5%af%bc%e8%88%aa%e5%ae%9e%e7%8e%b0'
title: 团购导航实现
wordpress_id: 48
categories:
- python
tags:
- pickle
- python
- 团购导航
---

前几天粗略构思了下，写了些简单的代码，主要是产品信息抓取的代码，网页抓去用了urllib，页面分析用了BeautifulSoup（貌似有内存问题，不过没发现，所以先用着）

抓去过的URL，不需要再次抓取，我就想着将所有抓取过的URL储存起来，每次都有新的都检查下是否存在，所以这个时候需要用到数据持久化的工具了，看了手册以后选择了pickle，可以储存对象，正好将我的url_list储存起来（性能暂时没有测试，等有时间测试下）。然后打算是每7天即一周新建一个url数据文件或者每一个站点对应一个url数据文件，每次都只比对最新的一个，这样数据量可以控制在比较小的范围内，不会拖累整个程序的速度。

先说这么多，下面附上pickle的用法：


    
    
    def get_old_urls(domain):
        file = "oldurls/%s" % domain
        old_urls = []
        if os.path.isfile(file):
            urls_file = open(file, "r")
            old_urls = pickle.load(urls_file)
            urls_file.close()
        return old_urls
    
    def update_ols_urls(domain, urls):
        file = "oldurls/%s" % domain
        urls_file = open(file, "w")
        pickle.dump(urls, urls_file)
        urls_file.close()
        return
    
